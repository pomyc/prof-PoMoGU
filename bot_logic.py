import os
import re
from flask import jsonify
from seniority_calculator import calculate_seniority
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv
from openai import OpenAI
from collections import Counter

# API –∫–ª—é—á OpenAI
openai_api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=openai_api_key)

if not openai_api_key:
    print("‚ùå OpenAI API key not found!")
else:
    print(f"‚úÖ OpenAI API key loaded: {openai_api_key[:10]}...")

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è FAISS –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏
try:
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectorstore = FAISS.load_local(
        "./knowledge_base", 
        embeddings,
        allow_dangerous_deserialization=True
    )
    print("üì¶ –í–µ–∫—Ç–æ—Ä–Ω–∞ –±–∞–∑–∞ FAISS —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
except Exception as e:
    print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–µ–∫—Ç–æ—Ä–Ω–æ—ó –±–∞–∑–∏: {e}")
    vectorstore = None

# –°—Ç–∞–Ω –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
user_state = {}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def handle_message(data):
    message_obj = data.get("message", {})
    message = message_obj.get("text")
    chat_id = message_obj.get("chat", {}).get("id")
    user_id = message_obj.get("from", {}).get("id")

    if not message or not chat_id:
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id or 0,
            "text": "‚ö†Ô∏è –Ø —Ä–æ–∑—É–º—ñ—é —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è."
        })

    if message.strip().lower() in ["/start", "start"]:
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": "üëã –í—ñ—Ç–∞—é! –Ø –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–æ–≤–∏–π –ø–æ–º—ñ—á–Ω–∏–∫. –û–±–µ—Ä—ñ—Ç—å –¥—ñ—é:",
            "reply_markup": {
                "keyboard": [
                    [{"text": "üìã –ó–∞–¥–∞—Ç–∏ –ø–∏—Ç–∞–Ω–Ω—è"}],
                    [{"text": "üìö –ó–∞–ø–∏—Ç –¥–æ –±–∞–∑–∏ –∑–Ω–∞–Ω—å"}],
                    [{"text": "üìÖ –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç—Ä—É–¥–æ–≤–æ–≥–æ —Å—Ç–∞–∂—É"}],
                    [{"text": "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–∏"}]
                ],
                "resize_keyboard": True
            }
        })

    if message == "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–∏":
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": "üìç –î–Ω—ñ–ø—Ä–æ, –ø—Ä. –î.–Ø–≤–æ—Ä–Ω–∏—Ü—å–∫–æ–≥–æ, 93, –æ—Ñ. 327\nüìû 050 324-54-11\nüìß profpmgu@gmail.com\nüåê http://pmguinfo.dp.ua"
        })

    if message == "üìÖ –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Ç—Ä—É–¥–æ–≤–æ–≥–æ —Å—Ç–∞–∂—É":
        user_state[user_id] = "awaiting_seniority_input"
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": "üìÖ –í–≤–µ–¥—ñ—Ç—å –¥–∞—Ç—É –ø–æ—á–∞—Ç–∫—É —Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è —Ä–æ–±–æ—Ç–∏ —á–µ—Ä–µ–∑ –∫—Ä–∞–ø–∫—É –∑ –∫–æ–º–æ—é (;)\n–ù–∞–ø—Ä–∏–∫–ª–∞–¥:\n01.09.2015; 24.04.2025\n–∞–±–æ —Ç—ñ–ª—å–∫–∏ –æ–¥–Ω—É –¥–∞—Ç—É, —è–∫—â–æ –¥–æ—Å—ñ –ø—Ä–∞—Ü—é—î—Ç–µ."
        })

    if user_state.get(user_id) == "awaiting_seniority_input":
        reply = calculate_seniority_input(message)
        user_state.pop(user_id, None)
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": reply
        })

    if message == "üìö –ó–∞–ø–∏—Ç –¥–æ –±–∞–∑–∏ –∑–Ω–∞–Ω—å":
        user_state[user_id] = "awaiting_knowledge_query"
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": "üìö –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç, —ñ —è —Å–ø—Ä–æ–±—É—é –∑–Ω–∞–π—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å:"
        })

    if user_state.get(user_id) == "awaiting_knowledge_query":
        reply = search_in_knowledge_base(message)
        user_state.pop(user_id, None)
        return jsonify({
            "method": "sendMessage",
            "chat_id": chat_id,
            "text": reply
        })

    # GPT ‚Äî –æ—Å–Ω–æ–≤–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    reply = ask_gpt_with_smart_context(message)
    return jsonify({
        "method": "sendMessage",
        "chat_id": chat_id,
        "text": reply
    })

# –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å—Ç–∞–∂—É
def calculate_seniority_input(message):
    try:
        if ";" in message:
            start_date, end_date = [d.strip() for d in message.split(";")]
            return calculate_seniority(start_date, end_date)
        else:
            return calculate_seniority(message.strip())
    except Exception:
        return "‚ö†Ô∏è –ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç. –ù–∞–ø–∏—à—ñ—Ç—å, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥:\n01.09.2015; 24.04.2025"

def is_document_relevant(result, query):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
    content = result.page_content.lower()
    source = result.metadata.get('source', '').lower()
    query_lower = query.lower()
    
    # –ñ–ï–°–¢–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    dues_keywords = ['–≤–Ω–µ—Å–æ–∫', '–≤–Ω–µ—Å–∫–∏', '–≤–∑–Ω–æ—Å', '–ø–ª–∞—Ç–∞', '—Ä–æ–∑–º—ñ—Ä', '—Å—É–º–∞', '—Å–∫—ñ–ª—å–∫–∏', '—è–∫–∏–π —Ä–æ–∑–º—ñ—Ä']
    is_dues_query = any(keyword in query_lower for keyword in dues_keywords)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
    election_indicators = [
        'vybory' in source,
        '–≤–∏–±–æ—Ä–∏' in source,
        '–≤–∏–±–æ—Ä—á–∞' in content,
        '–∑–≤—ñ—Ç–Ω–æ-–≤–∏–±–æ—Ä—á–∞' in content,
        '–≥–æ–ª–æ—Å—É–≤–∞–Ω–Ω—è' in content,
        '–∫–∞–Ω–¥–∏–¥–∞—Ç' in content
    ]
    
    is_election_document = any(election_indicators)
    
    # –ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å –æ –≤–∑–Ω–æ—Å–∞—Ö –∏ –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–π - –ë–õ–û–ö–ò–†–£–ï–ú
    if is_dues_query and is_election_document:
        print(f"üö´ –ë–õ–û–ö–ò–†–û–í–ê–ù –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞ –æ –≤–∑–Ω–æ—Å–∞—Ö: {source}")
        return False
    
    # –î–ª—è –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –¥—Ä—É–≥–∏—Ö —Å–ª—É—á–∞—è—Ö - —Ç–æ–∂–µ –±–ª–æ–∫–∏—Ä—É–µ–º
    if is_election_document and not any(term in query_lower for term in ['–≤–∏–±–æ—Ä–∏', '–≤–∏–±–æ—Ä—á–∞', '–∑–≤—ñ—Ç–Ω–æ-–≤–∏–±–æ—Ä—á–∞']):
        print(f"üö´ –ë–õ–û–ö–ò–†–û–í–ê–ù –∏–∑–±–∏—Ä–∞—Ç–µ–ª—å–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {source}")
        return False
    
    return True

def calculate_relevance_score(result, query):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏"""
    content = result.page_content.lower()
    source = result.metadata.get('source', '').lower()
    query_lower = query.lower()
    
    score = 0
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ (–∏—Å–∫–ª—é—á–∞—è –∫–æ—Ä–æ—Ç–∫–∏–µ)
    query_words = [word for word in re.findall(r'\w+', query_lower) if len(word) > 2]
    
    # –ë–∞–∑–æ–≤—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å–ª–æ–≤
    word_matches = 0
    for word in query_words:
        if word in content:
            score += 10
            word_matches += 1
    
    # –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å–ª–æ–≤ –º–µ–Ω—å—à–µ 30% –æ—Ç –∑–∞–ø—Ä–æ—Å–∞ - —Å—Ä–∞–∑—É –Ω–∏–∑–∫–∏–π –±–∞–ª–ª
    if len(query_words) > 0 and word_matches / len(query_words) < 0.3:
        score = max(score, 5)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –≤–∑–Ω–æ—Å–∞—Ö
    dues_keywords = ['–≤–Ω–µ—Å–æ–∫', '–≤–Ω–µ—Å–∫–∏', '–≤–∑–Ω–æ—Å', '–ø–ª–∞—Ç–∞', '—Ä–æ–∑–º—ñ—Ä', '—Å—É–º–∞', '—Å–∫—ñ–ª—å–∫–∏', '—è–∫–∏–π —Ä–æ–∑–º—ñ—Ä']
    is_dues_query = any(keyword in query_lower for keyword in dues_keywords)
    
    if is_dues_query:
        # –ö–ª—é—á–µ–≤—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –≤–∑–Ω–æ—Å–æ–≤
        high_value_terms = ['–≤–Ω–µ—Å–æ–∫', '–≤–Ω–µ—Å–∫–∏', '–ø–ª–∞—Ç–∞', '—Ä–æ–∑–º—ñ—Ä', '—Å—É–º–∞']
        context_terms = ['–≥—Ä–Ω', '–≥—Ä–∏–≤–µ–Ω—å', '–ø—Ä–æ—Ü–µ–Ω—Ç', '%', '—Å—Ç–∞–≤–∫–∞', '—Ç–∞—Ä–∏—Ñ', '–æ–ø–ª–∞—Ç–∞', '–∫–æ—à—Ç–∏', '–∑–∞—Ä–æ–±—ñ—Ç–Ω']
        
        financial_matches = 0
        
        # –í—ã—Å–æ–∫–∏–π –±–∞–ª–ª –∑–∞ –ø—Ä—è–º—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤–∑–Ω–æ—Å–æ–≤
        for term in high_value_terms:
            if term in content:
                score += 100
                financial_matches += 1
        
        # –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        for term in context_terms:
            if term in content:
                score += 20
                financial_matches += 1
        
        # –ï—Å–ª–∏ —ç—Ç–æ –≤–æ–ø—Ä–æ—Å –æ –≤–∑–Ω–æ—Å–∞—Ö, –Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ - –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –±–∞–ª–ª
        if financial_matches == 0:
            score = min(score, 5)
        
        # –°—É–ø–µ—Ä –±–æ–Ω—É—Å –∑–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ "—Å—Ç–∞—Ç—É—Ç" + —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        if '—Å—Ç–∞—Ç—É—Ç' in source and financial_matches > 0:
            score += 150
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ—Ä–∞–∑—ã –æ —Ä–∞–∑–º–µ—Ä–µ –≤–∑–Ω–æ—Å–æ–≤
        specific_phrases = [
            '—Ä–æ–∑–º—ñ—Ä –≤–Ω–µ—Å–∫', '—Å—É–º–∞ –≤–Ω–µ—Å–∫', '—Ä–æ–∑–º—ñ—Ä –ø–ª–∞—Ç', '—Å—É–º–∞ –ø–ª–∞—Ç',
            '—Å–∫—ñ–ª—å–∫–∏ –≤–Ω–µ—Å–∫', '—è–∫–∏–π –≤–Ω–µ—Å–æ–∫', '–ø—Ä–æ—Ü–µ–Ω—Ç –≤—ñ–¥ –∑–∞—Ä–ø–ª–∞—Ç', '–≤—ñ–¥—Å–æ—Ç–æ–∫ –≤—ñ–¥ –∑–∞—Ä–æ–±—ñ—Ç–Ω',
            '—á–ª–µ–Ω—Å—å–∫–∏–π –≤–Ω–µ—Å–æ–∫', '–ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–æ–≤–∏–π –≤–Ω–µ—Å–æ–∫'
        ]
        for phrase in specific_phrases:
            if phrase in content:
                score += 80
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç (–º–µ–Ω–µ–µ 100 —Å–∏–º–≤–æ–ª–æ–≤)
    if len(result.page_content) < 100:
        score -= 20
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏–ª–∏ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è
    title_indicators = ['–∑–∞—Ç–≤–µ—Ä–¥–∂–µ–Ω–æ', '—Å—Ç–∞—Ç—É—Ç', '–≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ—Ä–º—ñ–Ω—ñ–≤', '–∑–º—ñ—Å—Ç', '—Ä–æ–∑–¥—ñ–ª']
    title_matches = sum(1 for indicator in title_indicators if indicator in content)
    if title_matches >= 2 and len(result.page_content) < 200:
        score -= 30
    
    print(f"üî¢ –§–∞–π–ª: {source}, –∑–∞–ø—Ä–æ—Å: '{query[:30]}...', –±–∞–ª–ª: {score}")
    return score

def search_in_knowledge_base(query):
    """–ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    try:
        if not vectorstore:
            return "‚ö†Ô∏è –ë–∞–∑–∞ –∑–Ω–∞–Ω—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ."
        
        print(f"üîç –ü–æ—à—É–∫ —É –±–∞–∑—ñ –∑–Ω–∞–Ω—å: {query}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        results = vectorstore.similarity_search(query, k=15)
        
        if not results:
            return "üìö –£ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –Ω–∞ —Ü–µ –ø–∏—Ç–∞–Ω–Ω—è."
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        scored_results = []
        for result in results:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
            if not is_document_relevant(result, query):
                print(f"üö´ –ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù –¥–æ–∫—É–º–µ–Ω—Ç: {result.metadata.get('source', 'unknown')}")
                continue
                
            score = calculate_relevance_score(result, query)
            if score > 20:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                scored_results.append((result, score))
                print(f"‚úÖ –ü–†–ò–ù–Ø–¢ –¥–æ–∫—É–º–µ–Ω—Ç: {result.metadata.get('source', 'unknown')}, –±–∞–ª–ª: {score}")
            else:
                print(f"‚ùå –û–¢–ö–õ–û–ù–ï–ù –¥–æ–∫—É–º–µ–Ω—Ç: {result.metadata.get('source', 'unknown')}, –±–∞–ª–ª: {score}")
        
        print(f"üìä –í—Å–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}, –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(scored_results)}")
        
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å
        if not scored_results:
            return "üìö –£ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –Ω–∞ —Ü–µ –ø–∏—Ç–∞–Ω–Ω—è. –ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–∏ –∑–∞ –¥–µ—Ç–∞–ª—å–Ω–æ—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—î—é:\nüìû 050 324-54-11\nüìß profpmgu@gmail.com"
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-3
        scored_results.sort(key=lambda x: x[1], reverse=True)
        top_results = scored_results[:3]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = "üìñ –ó–Ω–∞–π–¥–µ–Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è:\n\n"
        
        for i, (result, score) in enumerate(top_results, 1):
            source = result.metadata.get('source', '–ù–µ–≤—ñ–¥–æ–º–µ –¥–∂–µ—Ä–µ–ª–æ')
            content = result.page_content.strip()
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if len(content) > 400:
                content = content[:400] + "..."
            
            response += f"üìÑ –î–∂–µ—Ä–µ–ª–æ: {source}\n"
            response += f"{content}\n"
            
            if i < len(top_results):
                response += "\n" + "="*30 + "\n\n"
        
        return response
        
    except Exception as e:
        print(f"‚ùå DB error: {e}")
        return "‚ö†Ô∏è –°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å."

def ask_gpt_with_smart_context(message):
    """GPT —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
    try:
        context = ""
        
        if vectorstore:
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
                results = vectorstore.similarity_search(message, k=10)
                
                if results:
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    scored_results = []
                    for result in results:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—É—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                        if not is_document_relevant(result, message):
                            continue
                            
                        score = calculate_relevance_score(result, message)
                        scored_results.append((result, score))
                    
                    # –°–¢–†–û–ì–ò–ô –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ - –∏—Å–∫–ª—é—á–∞–µ–º –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
                    min_score = 25  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
                    relevant_results = []
                    for result, score in scored_results:
                        if score >= min_score:
                            relevant_results.append((result, score))
                    
                    if relevant_results:
                        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-2 —Å–∞–º—ã—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö
                        relevant_results.sort(key=lambda x: x[1], reverse=True)
                        top_relevant = relevant_results[:2]
                        
                        context = "\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –∑ –±–∞–∑–∏ –∑–Ω–∞–Ω—å:\n"
                        for result, score in top_relevant:
                            source = result.metadata.get('source', '–¥–æ–∫—É–º–µ–Ω—Ç')
                            content = result.page_content[:300]
                            context += f"–ó {source} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å: {score}): {content}...\n\n"
                    else:
                        print("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –±–∞–ª 25)")
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–æ—à—É–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É: {e}")

        system_message = (
            "–¢–∏ –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ø–æ–º—ñ—á–Ω–∏–∫ –∑ –ø–∏—Ç–∞–Ω—å –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–æ–≤–æ—ó –¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ —Ç–∞ —Ç—Ä—É–¥–æ–≤–æ–≥–æ –ø—Ä–∞–≤–∞ –£–∫—Ä–∞—ó–Ω–∏. "
            "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é, –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–æ —Ç–∞ —Ç–æ—á–Ω–æ. "
            "–Ø–∫—â–æ –≤ –Ω–∞–¥–∞–Ω–æ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ —î —Ç–æ—á–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π —ó—ó. "
            "–Ø–∫—â–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –∞–±–æ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π - —á–µ—Å–Ω–æ —Å–∫–∞–∂–∏ –ø—Ä–æ —Ü–µ "
            "—ñ –¥–∞–π –∑–∞–≥–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∑–Ω–∞–Ω—å –ø—Ä–æ —Ç—Ä—É–¥–æ–≤–µ –ø—Ä–∞–≤–æ –£–∫—Ä–∞—ó–Ω–∏. "
            "–ü—Ä–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –ø–æ—Å–∏–ª–∞–π—Å—è –Ω–∞ —Å—Ç–∞—Ç—Ç—ñ –ö–ó–ø–ü –£–∫—Ä–∞—ó–Ω–∏. "
            "–Ø–∫—â–æ –Ω–µ –∑–Ω–∞—î—à —Ç–æ—á–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ - –∫—Ä–∞—â–µ –Ω–∞–ø—Ä–∞–≤ –¥–æ –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–∏ –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—î—é."
        )

        user_message = f"–ü–∏—Ç–∞–Ω–Ω—è: {message}"
        if context:
            user_message += f"\n{context}"
        else:
            user_message += "\n\n–ü—Ä–∏–º—ñ—Ç–∫–∞: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –≤ –±–∞–∑—ñ –∑–Ω–∞–Ω—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ],
            max_tokens=1000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"‚ùå GPT error: {e}")
        return (
            "üîç –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å.\n"
            "üìç –ó–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –ø—Ä–æ—Ñ—Å–ø—ñ–ª–∫–∏:\n"
            "–î–Ω—ñ–ø—Ä–æ, –ø—Ä. –î.–Ø–≤–æ—Ä–Ω–∏—Ü—å–∫–æ–≥–æ, 93, –∫.327\n"
            "üìû 050 324-54-11\n"
            "üìß profpmgu@gmail.com"
        )
